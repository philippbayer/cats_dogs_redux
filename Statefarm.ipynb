{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/statefarm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ubuntu/statefarm\n",
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu0')\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "#path = \"/home/ubuntu/statefarm/\"\n",
    "path = '/home/ubuntu/statefarm/sample/'\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, make the validation set with *different* drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cut -f 1 -d ',' driver_imgs_list.csv | grep -v subject | uniq -c\n",
    "lines=$(expr `wc -l driver_imgs_list.csv | cut -f 1 -d ' '` - 1)\n",
    "echo \"Got ${lines} pics\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastai's statefarm has 3478 pics in validation set and 18946 in training, so let's get something close to that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "to_get = set(['p081','p075', 'p072', 'p066', 'p064'])\n",
    "with open('driver_imgs_list.csv') as f:\n",
    "    next(f)\n",
    "    for line in csv.reader(f):\n",
    "        if line[0] in to_get:\n",
    "            if os.path.exists('train/%s/%s' %(line[1], line[2])):\n",
    "                os.popen('mv train/%s/%s valid/%s/%s'%(line[1], line[2], line[1], line[2]))\n",
    "\n",
    "import glob\n",
    "print('Training has', len(glob.glob('train/*/*jpg')))\n",
    "print('Validation has', len(glob.glob('valid/*/*jpg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's make a sample set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir /home/ubuntu/statefarm/sample\n",
    "mkdir /home/ubuntu/statefarm/sample/train\n",
    "for i in {0..9}; do mkdir /home/ubuntu/statefarm/sample/train/c${i}; done\n",
    "mkdir /home/ubuntu/statefarm/sample/valid\n",
    "for i in {0..9}; do mkdir /home/ubuntu/statefarm/sample/valid/c${i}; done\n",
    "mkdir /home/ubuntu/statefarm/sample/test\n",
    "for i in {0..9}; do mkdir /home/ubuntu/statefarm/sample/test/c${i}; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "%cd /home/ubuntu/statefarm/train\n",
    "g = glob.glob('c?/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "print(shuf[:5])\n",
    "for i in range(1500): copyfile(shuf[i], '../sample/train/' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd ../valid\n",
    "g = glob.glob('c?/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(1000): copyfile(shuf[i], '../sample/valid/' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "find /home/ubuntu/statefarm/sample/valid -type f | wc -l\n",
    "find /home/ubuntu/statefarm/sample/train -type f | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So we made a sample set now, hooray, now starts the actual work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "\n",
    "trn_batches = get_batches(path+'train', gen_t, batch_size=batch_size)\n",
    "val_batches = get_batches(path+'valid', batch_size=batch_size*2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from vgg16bn import Vgg16BN\n",
    "model = vgg_ft_bn(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE FOLLOWING TAKES FOREVER - TAKES MOST OF MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_data(path, target_size=(224,224)):\n",
    "    batches = get_batches(path, shuffle=False, batch_size=1, class_mode=None, target_size=target_size)\n",
    "    return np.concatenate([batches.next() for i in range(batches.nb_sample)])\n",
    "\n",
    "#trn = np.concatenate([trn_batches.next() for i in range(trn_batches.nb_sample)])\n",
    "#val = np.concatenate([val_batches.next() for i in range(val_batches.nb_sample)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(1e-3),\n",
    "       loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 62s - loss: 5.1128 - acc: 0.1787 - val_loss: 3.3818 - val_acc: 0.1390\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 62s - loss: 3.7676 - acc: 0.3100 - val_loss: 3.7121 - val_acc: 0.1730\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 62s - loss: 3.3112 - acc: 0.3700 - val_loss: 3.6866 - val_acc: 0.2080\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 62s - loss: 2.7351 - acc: 0.4447 - val_loss: 3.2837 - val_acc: 0.2570\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 62s - loss: 2.6851 - acc: 0.4767 - val_loss: 2.9753 - val_acc: 0.2820\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 62s - loss: 2.5379 - acc: 0.4780 - val_loss: 3.3070 - val_acc: 0.2740\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 62s - loss: 2.4977 - acc: 0.5027 - val_loss: 3.0505 - val_acc: 0.3310\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 62s - loss: 2.3929 - acc: 0.5247 - val_loss: 3.2969 - val_acc: 0.3200\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 62s - loss: 2.2617 - acc: 0.5293 - val_loss: 3.4493 - val_acc: 0.3100\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 62s - loss: 2.0739 - acc: 0.5600 - val_loss: 3.3178 - val_acc: 0.3560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd2fb8dfd10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(trn_batches, trn_batches.N, nb_epoch=10, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 62s - loss: 1.9820 - acc: 0.5620 - val_loss: 3.0467 - val_acc: 0.3660\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 62s - loss: 2.0741 - acc: 0.5700 - val_loss: 3.0053 - val_acc: 0.3850\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 62s - loss: 1.8943 - acc: 0.5820 - val_loss: 3.2091 - val_acc: 0.3600\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 62s - loss: 1.8415 - acc: 0.5953 - val_loss: 2.8547 - val_acc: 0.3820\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 62s - loss: 1.8956 - acc: 0.5960 - val_loss: 3.1333 - val_acc: 0.3920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd2a3e38dd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(trn_batches, trn_batches.N, nb_epoch=5, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layers,fc_layers = split_at(model, Convolution2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_feat = conv_model.predict_generator(trn_batches, trn_batches.N)\n",
    "conv_val_feat = conv_model.predict_generator(val_batches, val_batches.N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/statefarm/sample\n",
      "mkdir: cannot create directory ‘results’: File exists\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ubuntu/statefarm/sample\n",
    "%mkdir results\n",
    "\n",
    "save_array(path+'results/conv_val_feat.dat', conv_val_feat)\n",
    "save_array(path+'results/conv_feat.dat', conv_feat)\n",
    "print(type(conv_feat))\n",
    "\n",
    "conv_feat = load_array(path+'results/conv_feat.dat')\n",
    "conv_val_feat = load_array(path+'results/conv_val_feat.dat')\n",
    "print(type(conv_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        BatchNormalization(axis=1),\n",
    "        Dropout(p),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(10, activation='softmax')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "Found 0 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1500/1500 [==============================] - 1s - loss: 3.7744 - acc: 0.0967 - val_loss: 6.2962 - val_acc: 0.1320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd2f2af9ad0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=1, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 1000 samples\n",
      "Epoch 1/7\n",
      "1500/1500 [==============================] - 1s - loss: 2.6958 - acc: 0.2060 - val_loss: 4.5711 - val_acc: 0.1210\n",
      "Epoch 2/7\n",
      "1500/1500 [==============================] - 1s - loss: 2.2441 - acc: 0.2960 - val_loss: 3.3890 - val_acc: 0.1230\n",
      "Epoch 3/7\n",
      "1500/1500 [==============================] - 1s - loss: 1.8514 - acc: 0.3920 - val_loss: 3.2669 - val_acc: 0.1160\n",
      "Epoch 4/7\n",
      "1500/1500 [==============================] - 1s - loss: 1.4936 - acc: 0.5133 - val_loss: 2.9854 - val_acc: 0.1230\n",
      "Epoch 5/7\n",
      "1500/1500 [==============================] - 1s - loss: 1.1830 - acc: 0.5993 - val_loss: 3.0020 - val_acc: 0.0950\n",
      "Epoch 6/7\n",
      "1500/1500 [==============================] - 1s - loss: 0.9200 - acc: 0.6867 - val_loss: 3.1331 - val_acc: 0.1010\n",
      "Epoch 7/7\n",
      "1500/1500 [==============================] - 1s - loss: 0.6866 - acc: 0.7593 - val_loss: 3.1249 - val_acc: 0.0720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd2f2af9e90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.optimizer.lr = 1e-7\n",
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=7, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The validation accuracy is 10%, which is essentially random for for 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
